insight review articles

Exploring complex networks
Steven H. Strogatz
Department of Theoretical and Applied Mechanics and Center for Applied Mathematics, 212 Kimball Hall, Cornell University, Ithaca, New York 14853-1503, USA (e-mail: strogatz@cornell.edu)

The study of networks pervades all of science, from neurobiology to statistical physics. The most basic issues are structural: how does one characterize the wiring diagram of a food web or the Internet or the metabolic network of the bacterium Escherichia coli? Are there any unifying principles underlying their topology? From the perspective of nonlinear dynamics, we would also like to understand how an enormous network of interacting dynamical systems -- be they neurons, power stations or lasers -- will behave collectively, given their individual dynamics and coupling architecture. Researchers are only now beginning to unravel the structure and dynamics of complex networks.

etworks are on our minds nowadays. Sometimes we fear their power -- and with good reason. On 10 August 1996, a fault in two power lines in Oregon led, through a cascading series of failures, to blackouts in 11 US states and two Canadian provinces, leaving about 7 million customers without power for up to 16 hours1. The Love Bug worm, the worst computer attack to date, spread over the Internet on 4 May 2000 and inflicted billions of dollars of damage worldwide. In our lighter moments we play parlour games about connectivity. `Six degrees of Marlon Brando' broke out as a nationwide fad in Germany, as readers of Die Zeit tried to connect a falafel vendor in Berlin with his favourite actor through the shortest possible chain of acquaintances2. And during the height of the Lewinsky scandal, the New York Times printed a diagram3 of the famous people within `six degrees of Monica'. Meanwhile scientists have been thinking about networks too. Empirical studies have shed light on the topology of food webs4,5, electrical power grids, cellular and metabolic networks6­9, the World-Wide Web10, the Internet backbone11, the neural network of the nematode worm Caenorhabditis elegans12, telephone call graphs13, coauthorship and citation networks of scientists14­16, and the quintessential `old-boy' network, the overlapping boards of directors of the largest companies in the United States17 (Fig. 1). These databases are now easily accessible, courtesy of the Internet. Moreover, the availability of powerful computers has made it feasible to probe their structure; until recently, computations involving million-node networks would have been impossible without specialized facilities. Why is network anatomy so important to characterize? Because structure always affects function. For instance, the topology of social networks affects the spread of information and disease, and the topology of the power grid affects the robustness and stability of power transmission. From this perspective, the current interest in networks is part of a broader movement towards research on complex systems. In the words of E. O. Wilson18, "The greatest challenge today, not just in cell biology and ecology but in all of science, is the accurate and complete description of complex systems. Scientists have broken down many kinds of systems. They think they know most of the elements and forces. The next task is to reassemble them, at least in mathematical models that capture the key properties of the entire ensembles."
268

N

But networks are inherently difficult to understand, as the following list of possible complications illustrates. 1. Structural complexity: the wiring diagram could be an intricate tangle (Fig. 1). 2. Network evolution: the wiring diagram could change over time. On the World-Wide Web, pages and links are created and lost every minute. 3. Connection diversity: the links between nodes could have different weights, directions and signs. Synapses in
Box 1 Nonlinear dynamics: terminology and concepts97

Dynamical systems can often be modelled by differential equations dx/dt v(x), where x(t) (x1(t), ..., xn(t)) is a vector of state variables, t is time, and v(x) (v1(x), ..., vn(x)) is a vector of functions that encode the dynamics. For example, in a chemical reaction, the state variables represent concentrations. The differential equations represent the kinetic rate laws, which usually involve nonlinear functions of the concentrations. Such nonlinear equations are typically impossible to solve analytically, but one can gain qualitative insight by imagining an abstract n-dimensional state space with axes x1, ..., xn. As the system evolves, x(t) flows through state space, guided by the `velocity' field dx/dt v(x) like a speck carried along in a steady, viscous fluid. Suppose x(t) eventually comes to rest at some point x*. Then the velocity must be zero there, so we call x* a fixed point. It corresponds to an equilibrium state of the physical system being modelled. If all small disturbances away from x* damp out, x* is called a stable fixed point -- it acts as an attractor for states in its vicinity. Another long-term possibility is that x(t) flows towards a closed loop and eventually circulates around it forever. Such a loop is called a limit cycle. It represents a self-sustained oscillation of the physical system. A third possibility is that x(t) might settle onto a strange attractor, a set of states on which it wanders forever, never stopping or repeating. Such erratic, aperiodic motion is considered chaotic if two nearby states flow away from each other exponentially fast. Long-term prediction is impossible in a real chaotic system because of this exponential amplification of small uncertainties or measurement errors
NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com

© 2001 Macmillan Magazines Ltd

insight review articles
the nervous system can be strong or weak, inhibitory or excitatory. 4. Dynamical complexity: the nodes could be nonlinear dynamical systems. In a gene network or a Josephson junction array, the state of each node can vary in time in complicated ways. 5. Node diversity: there could be many different kinds of nodes. The biochemical network that controls cell division in mammals consists of a bewildering variety of substrates and enzymes6, only a few of which are shown in Fig. 1c. 6. Meta-complication: the various complications can influence each other. For example, the present layout of a power grid depends on how it has grown over the years -- a case where network evolution (2) affects topology (1). When coupled neurons fire together repeatedly, the connection between them is strengthened; this is the basis of memory and learning. Here nodal dynamics (4) affect connection weights (3). To make progress, different fields have suppressed certain complications while highlighting others. For instance, in nonlinear dynamics we have tended to favour simple, nearly identical dynamical systems coupled together in simple, geometrically regular ways. Furthermore we usually assume that the network architecture is static. These simplifications allow us to sidestep any issues of structural complexity and to concentrate instead on the system's potentially formidable dynamics. Laser arrays provide a concrete example19­24. In the single-mode approximation, each laser is characterized by its time-dependent gain, polarization, and the phase and amplitude of its electric field. These evolve according to four coupled, nonlinear differential equations. We usually hope the laser will settle down to a stable state, corresponding to steady emission of light, but periodic pulsations and even chaotic intensity fluctuations can occur in some cases19. Now suppose that many identical lasers are arranged side by side in a regular chain20 or ring21, interacting with their neighbours by evanescent coupling or by overlap of their electric fields22. Will the lasers lock their phases together spontaneously, or break up into a standing wave pattern, or beat each other into incoherence? From a technological standpoint, self-synchronization would be the most desirable outcome, because a perfectly coherent array of N lasers would
Figure 1 Wiring diagrams for complex networks. a, Food web of Little Rock Lake, Wisconsin, currently the largest food web in the primary literature5. Nodes are functionally distinct `trophic species' containing all taxa that share the same set of predators and prey. Height indicates trophic level with mostly phytoplankton at the bottom and fishes at the top. Cannibalism is shown with self-loops, and omnivory (feeding on more than one trophic level) is shown by different coloured links to consumers. (Figure provided by N. D. Martinez). b, New York State electric power grid. Generators and substations are shown as small blue bars. The lines connecting them are transmission lines and transformers. Line thickness and colour indicate the voltage level: red, 765 kV and 500 kV; brown, 345 kV; green, 230 kV; grey, 138 kV and below. Pink dashed lines are transformers. (Figure provided by J. Thorp and H. Wang). c, A portion of the molecular interaction map for the regulatory network that controls the mammalian cell cycle6. Colours indicate different types of interactions: black, binding interactions and stoichiometric conversions; red, covalent modifications and gene expression; green, enzyme actions; blue, stimulations and inhibitions. (Reproduced from Fig. 6a in ref. 6, with permission. Figure provided by K. Kohn.)
c

a

b

C14

P48
CAK

Transcription
P C42 cdk1 cdk

Cyclin box
P

C43

p16
C12 C10
p19ARF PT286

SL1
P

P

C14 C24

DMP1
C11 C11a

cdc25A
P
C20

C35 C31

Myc:Max

CycH

Cdk7

C11b

C8

P

C9
p16 PCNA

R11 C1

cycD
C34 C22

C3

cdk4/6
C32

Fos

Replication
R11
PCNA RPA P P CycE R2 CycA

Gadd45
R6
p53

R10 S9

CycD p21/Gadd45 CycA

P44 P43
P

p21 p27
p57 PT380

C7

R2

C21
p68

p68 primase Pol 

C23
PY15 P

R2 C13 C19 C2

P CycA Skp1 R1 CBF3

cycE
PS76

C26 C26
p68
RPA

C28

Skp2
R2 C27

C25

C4

cdk2
E20
P PS216
C38 C39 C37 C36 C40 C18

C29
C2

cycA
S9 C30 C41 C5 C15

p53 box
P

Chk1
C-TAK1

C11b
DMP1 p19ARF

p53

cycB
C42 C41

cdc25C
PT14Y15 PT161

SL1

P26
Mdm2
DP1 pRb E2F

?

APC
C41

P

C37

C17
P

cdk1
C16

Cks1

C6

Wee1
14-3-3

Myt1
P42
cyclins, pol 

NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com

E2F

Plk1

© 2001 Macmillan Magazines Ltd

269

insight review articles
system, its long-term behaviour is given by stable fixed points, limit cycles or chaotic attractors (Box 1). If we now couple many such systems together, what can be said about their collective behaviour? The answer is not much -- the details matter. But I will propose some rough generalizations anyway. If the dynamical system at each node has stable fixed points and no other attractors, the network tends to lock into a static pattern. Many such patterns may coexist, especially if the nodes have competing interactions. In that case the network may become frustrated and display enormous numbers of locally stable equilibria. This kind of complex static behaviour is seen in models of spin glasses, associative memory neural networks and combinatorial optimization problems33. At the opposite extreme, suppose each node has a chaotic attractor. Few rules have emerged about the effect of coupling architecture on dynamics in this case. It is known that networks of identical chaotic systems can synchronize their erratic fluctuations, a curious phenomenon with possible applications to private communications34,35. For a wide range of network topologies, synchronized chaos requires that the coupling be neither too weak nor too strong; otherwise spatial instabilities are triggered34. Related lines of research deal with networks of identical chaotic maps, lattice dynamical systems and cellular automata. These systems have been used mainly as testbeds for exploring spatiotemporal chaos and pattern formation in the simplest mathematical settings, rather than as models of real physical systems.
Identical oscillators

Figure 2 Spontaneous synchronization in a network of limit-cycle oscillators with distributed natural frequencies. The state of each oscillator is represented geometrically as a dot in the complex plane. The amplitude and phase of the oscillation correspond to the radius and angle of the dot in polar coordinates. Colours code the oscillators' natural frequencies, running from slowest (red) to fastest (violet). In the absence of coupling, each oscillator would settle onto its limit cycle (circle) and rotate at its natural frequency. However, here all the oscillators are also pulled towards the mean field that they generate collectively (shown as an asterisk at the centre of the population). Time increases from left to right, and from top to bottom. Starting from a random initial condition, the oscillators self-organize by collapsing their amplitudes; then they sort their phases so that the fastest oscillators are in the lead. Ultimately they all rotate as a synchronized pack, with locked amplitudes and phases. The governing equations describe a mean-field model of a laser array23. (Simulation provided by R. Oliva.)

produce N 2 times as much power as a single one. But in practice, semiconductor laser arrays are notoriously prone to both spatial and temporal instabilities20,21. Even for a simple ring geometry, this problem is dynamically complex. The first part of this article reviews what is known about dynamical complexity in regular networks of nonlinear systems. I offer a few rules of thumb about the impact of network structure on collective dynamics, especially for arrays of coupled limit-cycle oscillators. The logical next step would be to tackle networks that combine dynamical and structural complexity, such as power grids or ecological webs. Unfortunately they lie beyond our mathematical reach -- we do not even know how to characterize their wiring diagrams. So we have to begin with network topology. By a happy coincidence, such architectural questions are being pursued in other branches of science, thanks to the excitement about the Internet, functional genomics, financial networks, and so on. The second part of this article uses graph theory to explore the structure of complex networks, an approach that has recently led to some encouraging progress, especially when combined with the tools of statistical mechanics and computer simulations. Needless to say, many other topics within network science deserve coverage here. The subject is amazingly rich, and apologies are offered to those readers whose favourite topics are omitted.

Regular networks of coupled dynamical systems
Networks of dynamical systems have been used to model everything from earthquakes to ecosystems, neurons to neutrinos25­32. To impose some order on this list, consider the dynamics that each node would exhibit if it were isolated. Assuming it is a generic dynamical
270

The intermediate case where each node has a stable limit cycle has turned out to be particularly fruitful. Much of the research has been inspired by biological examples, ranging from the mutual synchronization of cardiac pacemaker cells, to rhythmically flashing fireflies and chorusing crickets, to wave propagation in the heart, brain, intestine and nervous system25. Arrays of identical oscillators often synchronize, or else form patterns that depend on the symmetry of the underlying network36. Other common modes of organization are travelling waves in one spatial dimension, rotating spirals in two dimensions and scroll waves in three dimensions25,26. For fully connected networks where each node is coupled equally to all the others, the completely synchronized state becomes likely. These heuristics apply to systems coupled by smooth interactions akin to diffusion. But many biological oscillators communicate by sudden impulses: a neuron fires, a firefly flashes, a cricket chirps. Hence the recent interest in pulse-coupled oscillators37. This thread began with Peskin's model of the sinoatrial node, the heart's natural pacemaker, as a collection of N identical integrate-and-fire oscillators38. For the simple case where each oscillator is connected to all the others, Peskin conjectured that they would all end up firing in unison, no matter how they started. He gave a proof for N 2 oscillators; it was later demonstrated39 that the conjecture holds for all N. Peskin also conjectured that synchronization would occur even if the oscillators were not quite identical, but that problem remains unproven. Peskin's model has been used as a caricature of coupled neurons40­42 by including synaptic delays, refractory periods, inhibition and local coupling; these realistic features also remove some of the undesirable discontinuities in the mathematics. In an example of scientific cross-fertilization, Hopfield43 pointed out that the locally coupled version of the model is closely related to slider-block models of earthquakes and should therefore display self-organized criticality. That observation suggested intriguing links among neurobiology, geophysics, synchronization and self-organized criticality, and sparked a burst of research activity, as reviewed in ref. 37.
Non-identical oscillators

While modelling populations of biological oscillators, Winfree discovered a new kind of cooperative phenomenon, the temporal
NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com

© 2001 Macmillan Magazines Ltd

insight review articles
analogue of a phase transition44. He proposed a mean-field model of nearly identical, weakly coupled limit-cycle oscillators and showed that when the coupling is small compared to the spread of natural frequencies, the system behaves incoherently, with each oscillator running at its natural frequency. As the coupling is increased, the incoherence persists until a certain threshold is crossed -- then a small cluster of oscillators suddenly `freezes' into synchrony. For still greater coupling, all the oscillators become locked in phase and amplitude (Fig. 2). Kuramoto26 refined this connection between nonlinear dynamics and statistical physics. He proposed an exactly solvable model of collective synchronization, given by d i dt + K N sin( Nj 1 ), i 1, ..., N

a

b

i

j

i

where i(t) is the phase of the ith oscillator and i is its natural frequency, chosen at random from a lorentzian probability density
c

g( )

[ 2+(

0

)2]

of width and mean 0. Using an ingenious self-consistency argument, Kuramoto solved for the order parameter r(t) 1 Nj
N

ei
1

j (t)

(a convenient measure of the extent of synchronization) in the limit N and t . He found that r
d

0, 1 (Kc /K ),

K < Kc K Kc

where Kc 2 . In other words, the oscillators are desynchronized completely until the coupling strength K exceeds a critical value Kc. After that, the population splits into a partially synchronized state

Figure 3 Schematic illustration of regular and random network architectures. a, Ring of ten nodes connected to their nearest neighbours. b, Fully connected network of ten nodes. c, Random graph constructed by placing n nodes on a plane, then joining pairs of them together at random until m links are used. Nodes may be chosen more than once, or not at all. The resulting wiring diagram (not shown) would be a snarl of crisscrossed lines; to clarify it, I have segregated the different connected components, coloured them, and eliminated as many spurious crossings as possible. The main topological features are the presence of a single giant component, as expected51­53 for a random graph with m > n/2 (here n 200, m 193), and the absence of any dominant hubs. The degree, or number of neighbours, is Poisson distributed across the nodes; most nodes have between one and four neighbours, and all have between zero and six. d, Scale-free graph, grown by attaching new nodes at random to previously existing nodes. The probability of attachment is proportional to the degree of the target node; thus richly connected nodes tend to get richer, leading to the formation of hubs and a skewed degree distribution with a heavy tail. Colours indicate the three nodes with the most links (red, k 33 links; blue, k 12; green, k 11). Here n 200 nodes, m 199 links. Figure provided by D. Callaway. Network visualization was done using the Pajek program for large network analysis (http://vlado.fmf.uni-lj.si/pub/networks/pajek/pajekman.htm).
NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com

Figure 4 Solvable model of a small-world network. The model starts with a ring lattice of n nodes, each connected to its neighbours out to some range k (here n 24 and k 3). Shortcut links are added between random pairs of nodes, with probability per link on the underlying lattice. In the limit n 1, the average path length between nodes can be approximated analytically. (Adapted from ref. 75.)

© 2001 Macmillan Magazines Ltd

271

insight review articles
0.3

everyone's delight, that prediction was later confirmed by their experimental collaborators50.

Complex network architectures
0.2 l /n

0.1

All the network topologies discussed so far -- chains, grids, lattices and fully-connected graphs -- have been completely regular (Fig. 3a, b). Those simple architectures allowed us to focus on the complexity caused by the nonlinear dynamics of the nodes, without being burdened by any additional complexity in the network structure itself. Now I take the complementary approach, setting dynamics aside and turning to more complex architectures. A natural place to start is at the opposite end of the spectrum from regular networks, with graphs that are completely random.
0.01 0.1 1 nk 10 100 1,000 10,000

0.0 0.001

Random graphs

Figure 5 Average path length, normalized by system size, is plotted as a function of the average number of shortcuts. The circles are results from simulations of the model with range k 1 and size up to n 107 nodes. The solid line is given by the formula in the text. (Adapted from ref. 75.)

consisting of two groups of oscillators: a synchronized group that contributes to the order parameter r, and a desynchronized group whose natural frequencies lie in the tails of the distribution g( ) and are too extreme to be entrained. With further increases in K, more and more oscillators are recruited into the synchronized group, and r grows accordingly. Twenty-five years later, the Kuramoto model continues to surprise us (see ref. 45 for a review). First, the incoherent state with r 0 was found to be neutrally stable below threshold, despite its apparent stability in simulations; the analysis reveals a connection to Landau damping in plasmas. Second, the square-root critical behaviour of r, almost a cliché for mean-field models in statistical mechanics, turns out to be non-generic; if the sinusoidal coupling is replaced by a periodic function with second harmonics, the scaling changes to r ~ K Kc. Third, although the model was motivated originally by biological oscillators, it has appeared in such far-flung settings as the flavour evolution of neutrinos32, and arrays of Josephson junctions27 and semiconductor lasers24. The main unsolved problem is the stability of the partially synchronized state for K > Kc. Numerical simulations indicate that it is globally stable, in the sense that it attracts almost all solutions, but even the linear stability problem has yet to be solved. Another issue concerns the extension of the model to nearest-neighbour coupling on a d-dimensional cubic lattice. Simulations46 and renormalization arguments47 indicate that the synchronization phase transition persists for d 3 and vanishes for d 1; the results are ambiguous for d 2. All of this awaits a mathematical resolution. In contrast to the mean-field models of Winfree and Kuramoto, Ermentrout and Kopell's classic work deals with one-dimensional chains of oscillators, first in connection with neuromuscular rhythms in the mammalian intestine48, and later in their model of the central pattern generator for the lamprey eel49,50. The main phenomena here involve travelling waves, rather than the synchrony found in mean-field models. This is not accidental, as wave propagation is essential for the generation of peristalsis in the intestine, and for the creation of the swimming rhythm in lamprey. Ermentrout and Kopell introduced several deep mathematical innovations, but perhaps their most impressive result is a counterintuitive biological prediction. Their lamprey model suggested that the tail-to-head neural connections along the spinal cord would be stronger than those running from head to tail, despite the fact that the wave associated with swimming travels from head to tail. To
272

Imagine n 1 buttons strewn across the floor51. Pick two buttons at random and tie them together with thread. Repeat this process m times, always choosing pairs of buttons at random. (If m is large, you might eventually select buttons that already have threads attached. That is certainly allowed; it merely creates clusters of connected buttons.) The result is a physical example of a random graph with n nodes and m links (Fig. 3c). Now slowly lift a random button off the floor. If it is tied to other buttons, either directly or indirectly, those are dragged up too. So what happens? Are you likely to pull up an isolated button, a small cluster or a vast meshwork? Erdös and Rényi52 studied how the expected topology of this random graph changes as a function of m. When m is small, the graph is likely to be fragmented into many small clusters of nodes, called components. As m increases, the components grow, at first by linking to isolated nodes and later by coalescing with other components. A phase transition occurs at m n/2, where many clusters crosslink spontaneously to form a single giant component. For m > n/2, this giant component contains on the order of n nodes (more precisely, its size scales linearly with n, as n ), while its closest rival contains only about log n nodes. Furthermore, all nodes in the giant component are connected to each other by short paths: the maximum number of `degrees of separation' between any two nodes grows slowly, like log n. In the decades since this pioneering work, random graphs have been studied deeply within pure mathematics53. They have also served as idealized coupling architectures for dynamical models of gene networks, ecosystems and the spread of infectious diseases and computer viruses29,51,54,55.
Small-world networks

Although regular networks and random graphs are both useful idealizations, many real networks lie somewhere between the extremes of order and randomness. Watts and Strogatz56,57 studied a simple model that can be tuned through this middle ground: a regular lattice
Table 1 Clustering for three affiliation networks
Network Theory Company directors Movie actors Biomedical authors 0.590 0.084 0.042 Clustering C Actual 0.588 0.199 0.088

US corporate directors: 7,673 company directors linked by joint membership on 914 boards of the Fortune 1,000 companies for 1999. Movie actors: 449,913 actors linked by mutual appearances in 151,261 feature films, as specified by the Internet Movie Database (www.imdb.com) as of 1 May 2000. Biomedical collaborations: 1,388,989 scientists linked by coauthorship of at least one of 2,156,769 biomedical journal articles published between 1995 and 1999 inclusive, as listed in the MEDLINE database. The clustering coefficient C is defined as the probability that a connected triple of nodes is actually a triangle; here nodes correspond to people, as in the unipartite representation shown in Fig. 7b. Intuitively, C measures the likelihood that two people who have a mutual collaborator are also collaborators of each other. The results show that the random model accurately predicts C for the corporate director network, given the network's bipartite structure and its degree distributions; no additional social forces need to be invoked. For the networks of actors and scientists, the model accounts for about half of the observed clustering. The remaining portion depends on social mechanisms at work in these communities (see text). (Adapted from ref. 91.)

© 2001 Macmillan Magazines Ltd

NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com

insight review articles
Figure 6 Degree distributions for real networks. a, World-Wide Web. Nodes are web pages; links are directed URL hyperlinks from one page to another. The log­log plot shows the number of web pages that have a given in-degree (number of incoming links). The raw data have been logarithmically binned, with bin ratio 2. The tail of the distribution follows an approximate power law with exponent  2.2. (Adapted from ref. 10.) b, Coauthorship networks. Nodes represent scientists; an undirected link between two people means that they have written a paper together. The data are for the years 1995­1999 inclusive and come from three databases: arxiv.org (preprints mainly in theoretical physics), SPIRES (preprints in high-energy physics) and NCSTRL (preprints in computer science). Symbols denote different scientific communities: astrophysics (circles), condensed-matter physics (squares), high-energy physics (upright triangles) and computer science (inverted triangles). The log­log plot shows that the probability of having a total of z coauthors is well approximated by a truncated power law (solid line) of the form pz ~ z exp( z/z c), where z c is the cutoff. The curves have been displaced vertically for clarity. (Adapted from ref. 14.) c, Power grid of the western United States and Canada. Nodes represent generators, transformers and substations; undirected links represent high-voltage transmission lines between them. The data are plotted as a cumulative distribution to reduce the effects of noise on this smaller data set. The linear­log plot shows that the proportion of nodes with at least k transmission lines decays exponentially in k. The negative derivative of this cumulative distribution is the degree distribution, also an exponential. (Adapted from ref. 62.) d, Social network. Nodes are 43 Mormons in Utah; undirected links represent acquaintances with other Mormons79. The linear­log plot of the cumulative distribution is well fit by an error function (solid line), so the degree distribution is a gaussian. (Adapted from ref. 62.)

a 108

b

Frequency

106

104

102

100 100 c 10 0 Cumulative probability

101

10 2 Indegree

103

104 d

1

100 10 Number of coauthors 10
0

101

10 2 101 10 3

10 4 0 15 5 10 Transmission lines

20

0

100

200 300 Acquaintances

where the original links are replaced by random ones with some probability 0 1. They found that the slightest bit of rewiring transforms the network into a `small world', with short paths between any two nodes, just as in the giant component of a random graph. Yet the network is much more highly clustered than a random graph, in the sense that if A is linked to B and B is linked to C, there is a greatly increased probability that A will also be linked to C (a property that sociologists58 call `transitivity'). Watts and Strogatz conjectured that the same two properties -- short paths and high clustering -- would hold also for many natural and technological networks. Furthermore, they conjectured that dynamical systems coupled in this way would display enhanced signal propagation speed, synchronizability and computational power, as compared with regular lattices of the same size. The intuition is that the short paths could provide high-speed communication channels between distant parts of the system, thereby facilitating any dynamical process (like synchronization or computation) that requires global coordination and information flow. Research has proceeded along several fronts. Many empirical examples of small-world networks have been documented, in fields ranging from cell biology to business9,14,59­64. On the theoretical side, small-world networks are turning out to be a Rorschach test -- different scientists see different problems here, depending on their disciplines. Computer scientists see questions about algorithms and their complexity. Walsh65 showed that graphs associated with many difficult search problems have a small-world topology. Kleinberg66 introduced an elegant model of the algorithmic challenge posed by Milgram's original sociological experiment67 -- how to actually find a short chain of acquaintances linking yourself to a random target person, using only local information -- and he proved that the problem is easily solvable for some kinds of small worlds, and essentially intractable for others. Epidemiologists have asked how local clustering and global
NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com

contacts together influence th