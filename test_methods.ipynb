{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7855d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kpe import graph_based_methods as gr\n",
    "from kpe import statistical_based_mthods as stats\n",
    "from kpe import neural_networks_based_methods as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60a5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplearning = \"\"\"Deep learning (also known as deep structured learning) is part of a broader family of machine\n",
    "    learning methods based on artificial neural networks with representation learning. Learning can be supervised,\n",
    "    semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, \n",
    "    deep reinforcement learning, recurrent neural networks and convolutional neural networks have been applied to \n",
    "    fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, \n",
    "    drug design, medical image analysis, climate science, material inspection and board game programs, where they have\n",
    "    produced results comparable to and in some cases surpassing human expert performance. Artificial neural networks\n",
    "    (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have \n",
    "    various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic,\n",
    "    while the biological brain of most living organisms is dynamic (plastic) and analogue\n",
    "    \"\"\" \n",
    "\n",
    "nlp = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence \n",
    "    concerned with the interactions between computers and human language, in particular how to program computers to process\n",
    "    and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of \n",
    "    documents, including the contextual nuances of the language within them. The technology can then accurately extract \n",
    "    information and insights contained in the documents as well as categorize and organize the documents themselves.\"\"\"\n",
    "\n",
    "\n",
    "iran = \"\"\"The history of Iran is intertwined with the history of a larger region known as Greater Iran, comprising the \n",
    "    area from Anatolia in the west to the borders of Ancient India and the Syr Darya in the east, and from the Caucasus \n",
    "    and the Eurasian Steppe in the north to the Persian Gulf and the Gulf of Oman in the south. Central to this area is \n",
    "    Iran, commonly known until the mid-20th century as Persia in the Western world.Iran is home to one of the world's \n",
    "    oldest continuous major civilizations, with historical and urban settlements dating back to 4000 BC.[1] The south-western\n",
    "    and western part of the Iranian plateau participated in the traditional ancient Near East with Elam (3200–539 BC), \n",
    "    from the Bronze Age, and later with various other peoples, such as the Kassites, Mannaeans, and Gutians. Georg Wilhelm \n",
    "    Friedrich Hegel calls the Persians the \"first Historical People\".[2] The Medes unified Iran as a nation and empire \n",
    "    in 625 BC.[3] The Achaemenid Empire (550–330 BC), founded by Cyrus the Great, was the first true global superpower\n",
    "    state[4] and it ruled from the Balkans to North Africa and also Central Asia, spanning three continents, from their\n",
    "    seat of power in Persis (Persepolis). It was the largest empire yet seen and the first world empire.[5] The Achaemenid \n",
    "    Empire was the only civilization in all of history to connect over 40% of the global population, accounting for\n",
    "    approximately 49.4 million of the world's 112.4 million people in around 480 BC.[6] They were succeeded by the \n",
    "    Seleucid, Parthian, and Sasanian Empires, who successively governed Iran for almost 1,000 years and made Iran once \n",
    "    again a leading power in the world. Persia's arch-rival was the Roman Empire and its successor, the Byzantine Empire.\"\"\"\n",
    "\n",
    "\n",
    "# the first two document are quit clean but the last one is noisy and longer than the others. so extracting keywords \n",
    "# from that is a bit more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0daef",
   "metadata": {},
   "source": [
    "<h2>1. Graph based methods.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a8d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rank = gr.TextRank()\n",
    "pos_rank  = gr.SingleRank()\n",
    "frake = gr.Frake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd57902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc1 with [TextRank]: \n",
      "\tdeep learning            : 5.0539\n",
      "\tdeep neural              : 4.5581\n",
      "\tlearning                 : 3.125\n",
      "\tbiological               : 2.7\n",
      "\tneural                   : 2.6292\n",
      "\n",
      "-Keywords extracted from doc1 with [PositionalRank]: \n",
      "\tdeep learning            : 4.9874\n",
      "\tneural networks          : 4.8683\n",
      "\tdeep neural              : 4.7718\n",
      "\tlearning methods         : 4.2127\n",
      "\tmachine learning         : 4.071\n",
      "\n",
      "-Keywords extracted from doc1 with [Frake]: \n",
      "\tdeep learning machine neural networks: 47.98\n",
      "\tartificial networks biological: 23.43\n",
      "\tartificial neural biological: 20.86\n",
      "\tlearning machine         : 16.76\n",
      "\tnetworks                 : 13.51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omid\\Anaconda3\\envs\\tf\\lib\\site-packages\\networkx-2.8.6-py3.8.egg\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    }
   ],
   "source": [
    "doc1_cleaned = gr.TextRank.preprocess(deeplearning)\n",
    "\n",
    "kws_1_1 = text_rank.extract(doc1_cleaned, top=5)\n",
    "kws_2_1 = pos_rank.extract(doc1_cleaned, top=5 )\n",
    "kws_3_1 = frake.extract(doc1_cleaned, top=5, )\n",
    "\n",
    "for kws, method in zip([kws_1_1, kws_2_1, kws_3_1], [\"TextRank\", \"PositionalRank\", \"Frake\"]):\n",
    "    print(f\"-Keywords extracted from doc1 with [{method}]: \")\n",
    "    for k, s in kws.items():\n",
    "        print(f\"\\t{k:25}: {round(s, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5450c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc2 with [TextRank]: \n",
      "\tlanguage processing      : 4.3375\n",
      "\tlanguage                 : 3.125\n",
      "\tcomputer                 : 2.7\n",
      "\tlarge                    : 1.85\n",
      "\tintelligence             : 1.85\n",
      "\n",
      "-Keywords extracted from doc2 with [PositionalRank]: \n",
      "\tlanguage processing      : 4.2237\n",
      "\tnatural language         : 3.4799\n",
      "\thuman language           : 3.4268\n",
      "\tlanguage data            : 3.4268\n",
      "\tlinguistics computer     : 3.1333\n",
      "\n",
      "-Keywords extracted from doc2 with [Frake]: \n",
      "\tlanguage computer        : 15.02\n",
      "\tlanguage                 : 10.74\n",
      "\tdocuments                : 4.87\n",
      "\tcomputers                : 4.61\n",
      "\tcomputer                 : 4.28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omid\\Anaconda3\\envs\\tf\\lib\\site-packages\\networkx-2.8.6-py3.8.egg\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    }
   ],
   "source": [
    "doc2_cleaned = gr.TextRank.preprocess(nlp)\n",
    "\n",
    "kws_1_2 = text_rank.extract(doc2_cleaned, top=5)\n",
    "kws_2_2 = pos_rank.extract(doc2_cleaned, top=5 )\n",
    "kws_3_2 = frake.extract(doc2_cleaned, top=5, )\n",
    "\n",
    "for kws, method in zip([kws_1_2, kws_2_2, kws_3_2], [\"TextRank\", \"PositionalRank\", \"Frake\"]):\n",
    "    print(f\"-Keywords extracted from doc2 with [{method}]: \")\n",
    "    for k, s in kws.items():\n",
    "        print(f\"\\t{k:25}: {round(s, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240e4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc3 with [TextRank]: \n",
      "\tempire                   : 3.125\n",
      "\tsettlements              : 1.85\n",
      "\tmajor                    : 1.85\n",
      "\tasia                     : 1.85\n",
      "\twestern                  : 1.85\n",
      "\n",
      "-Keywords extracted from doc3 with [PositionalRank]: \n",
      "\tworld empire             : 3.7583\n",
      "\tachaemenid empire        : 3.625\n",
      "\troman empire             : 3.475\n",
      "\tbyzantine empire         : 3.375\n",
      "\tempire                   : 3.125\n",
      "\n",
      "-Keywords extracted from doc3 with [Frake]: \n",
      "\tachaemenid empire bc global: 27.87\n",
      "\tiran bc                  : 22.49\n",
      "\tiran known area          : 18.47\n",
      "\tempire                   : 12.81\n",
      "\tiran                     : 12.51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omid\\Anaconda3\\envs\\tf\\lib\\site-packages\\networkx-2.8.6-py3.8.egg\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    }
   ],
   "source": [
    "doc3_cleaned = gr.TextRank.preprocess(iran)\n",
    "\n",
    "kws_1_3 = text_rank.extract(doc3_cleaned, top=5)\n",
    "kws_2_3 = pos_rank.extract(doc3_cleaned, top=5 )\n",
    "kws_3_3 = frake.extract(doc3_cleaned, top=5)\n",
    "\n",
    "for kws, method in zip([kws_1_3, kws_2_3, kws_3_3], [\"TextRank\", \"PositionalRank\", \"Frake\"]):\n",
    "    print(f\"-Keywords extracted from doc3 with [{method}]: \")\n",
    "    for k, s in kws.items():\n",
    "        print(f\"\\t{k:25}: {round(s, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac770d",
   "metadata": {},
   "source": [
    "<h2>2. Statistical based methods.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b7c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading documents ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:16<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf = stats.TFIDF(path_to_docs=\"./sample_docs/\")\n",
    "yake  = stats.Yake(top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a89ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc1 with [TF-IDF]: \n",
      "\tneural networks deep     : 1.0935\n",
      "\tdeep neural networks     : 1.0935\n",
      "\tsupervised deep learning : 1.0242\n",
      "\tlearning learning        : 0.9601\n",
      "\tlearning recurrent neural: 0.9558\n",
      "\n",
      "-Keywords extracted from doc1 with [Yake]: \n",
      "\tartificial neural networks: 0.0003\n",
      "\tspecifically artificial neural: 0.0006\n",
      "\trecurrent neural networks: 0.0008\n",
      "\tconvolutional neural networks: 0.0008\n",
      "\tneural networks tend     : 0.0008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kws_4_1 = tfidf.extract(deeplearning, top=5)\n",
    "kws_5_1 = yake.extract(deeplearning)\n",
    "\n",
    "for kws, method in zip([kws_4_1, kws_5_1], [\"TF-IDF\", \"Yake\"]):\n",
    "    print(f\"-Keywords extracted from doc1 with [{method}]: \")\n",
    "    for k, s in kws.items():\n",
    "        print(f\"\\t{k:25}: {round(s, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2324109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc2 with [TF-IDF]: \n",
      "\tnatural language processing: 0.7559\n",
      "\tnatural language         : 0.642\n",
      "\tlanguage processing      : 0.5695\n",
      "\thuman language           : 0.558\n",
      "\tdocuments                : 0.5137\n",
      "\n",
      "-Keywords extracted from doc2 with [Yake]: \n",
      "\tnatural language data    : 0.0006\n",
      "\tartificial intelligence concerned: 0.0007\n",
      "\tanalyze large amounts    : 0.0007\n",
      "\taccurately extract information: 0.0007\n",
      "\tnatural language processing: 0.0008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kws_4_1 = tfidf.extract(nlp, top=5)\n",
    "kws_5_2 = yake.extract(nlp)\n",
    "\n",
    "for kws, method in zip([kws_4_1, kws_5_2], [\"TF-IDF\", \"Yake\"]):\n",
    "    print(f\"-Keywords extracted from doc2 with [{method}]: \")\n",
    "    for k, s in kws.items():\n",
    "        print(f\"\\t{k:25}: {round(s, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1798cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc3 with [TF-IDF]: \n",
      "\twestern world            : 0.558\n",
      "\tsouth western            : 0.463\n",
      "\tmillion people           : 0.342\n",
      "\thistorical people        : 0.342\n",
      "\tsouth west               : 0.3248\n",
      "\n",
      "-Keywords extracted from doc3 with [Yake]: \n",
      "\tgreater iran comprising  : 0.0002\n",
      "\tmedes unified iran       : 0.0002\n",
      "\tsuccessively governed iran: 0.0002\n",
      "\tworlds oldest continuous : 0.0002\n",
      "\ttrue global superpower   : 0.0003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\NLP\\KeyPhrases-Extraction\\kpe\\statistical_based_mthods.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tri_ = pd.Series(tri_).sort_values(ascending=False).iloc[:2*2]\n"
     ]
    }
   ],
   "source": [
    "kws_4_3 = tfidf.extract(iran, top=5)\n",
    "kws_5_3 = yake.extract(iran)\n",
    "\n",
    "for kws, method in zip([kws_4_3, kws_5_3], [\"TF-IDF\", \"Yake\"]):\n",
    "    print(f\"-Keywords extracted from doc3 with [{method}]: \")\n",
    "    for k, s in kws.items():\n",
    "        print(f\"\\t{k:25}: {round(s, 4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239fcb8",
   "metadata": {},
   "source": [
    "<h2>3. Transformer based method</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ec3fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model: distilbert-base-nli-mean-tokens\n"
     ]
    }
   ],
   "source": [
    "transformer = nn.KPESentenceTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428c89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc1 with [Transformer]: \n",
      "\tdeep learning\n",
      "\tmachine translation\n",
      "\tlearning architectures\n",
      "\tdeep neural\n",
      "\tbioinformatics drug\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kws_6_1 = transformer.extract(deeplearning)\n",
    "\n",
    "for kws, method in zip([kws_6_1], [\"Transformer\"]):\n",
    "    print(f\"-Keywords extracted from doc1 with [{method}]: \")\n",
    "    for k in kws:\n",
    "        print(f\"\\t{k}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e46309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc1 with [Transformer]: \n",
      "\tcomputer capable\n",
      "\tinformation insights\n",
      "\tsubfield linguistics\n",
      "\tlinguistics\n",
      "\tcomputer science\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kws_6_2 = transformer.extract(nlp)\n",
    "\n",
    "for kws, method in zip([kws_6_2], [\"Transformer\"]):\n",
    "    print(f\"-Keywords extracted from doc1 with [{method}]: \")\n",
    "    for k in kws:\n",
    "        print(f\"\\t{k}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1704f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Keywords extracted from doc1 with [Transformer]: \n",
      "\twestern iranian\n",
      "\tworld iran\n",
      "\tlargest empire\n",
      "\tcivilizations historical\n",
      "\tnorth persian\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kws_6_3 = transformer.extract(iran)\n",
    "\n",
    "for kws, method in zip([kws_6_3], [\"Transformer\"]):\n",
    "    print(f\"-Keywords extracted from doc1 with [{method}]: \")\n",
    "    for k in kws:\n",
    "        print(f\"\\t{k}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949f235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
